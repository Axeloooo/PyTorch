{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPesD0Wg83fA2LOd7FhJ50e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axeloooo/PyTorch/blob/main/04_pytorch_custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets"
      ],
      "metadata": {
        "id": "_ukzh1HYNYSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "6zUOi5lfkYwS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Z8WKriNRCW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "R6s7VujXk2JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "5YwzBgoHlPry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "Our dataset is a subset of the Food101 dataset.\n",
        "\n",
        "Food101 start 101 different classes of food and 1000 images per class (750 training and 250 testing).\n",
        "\n",
        "Our dataset starts with 3 classes of food and only 10% of the images (~75 training, 25 testing).\n",
        "\n",
        "When staring ML projects, it's important to try things on a small scale and then increase the scale when necessary."
      ],
      "metadata": {
        "id": "0ifunamZmA81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to a data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't ecist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exists... skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exist, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza, steak and sushi data...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "IUsydxovlR37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Becoming one with the data (data preparation and data exploration)"
      ],
      "metadata": {
        "id": "xn_9Ta6aoyIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"
      ],
      "metadata": {
        "id": "bJPij1Ngo2kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "1cLcDatIpaiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "Ffz6VO9bqYx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Visualizing an image\n",
        "\n",
        "Let's write some code to:\n",
        "1. Get all of the image paths\n",
        "2. Pick a random image path using Python's `random.choice()`\n",
        "3. Get the image class name using `pathlib.Path.parent.stem`\n",
        "4. Since we're working with images let's open the image with Python's PIL\n",
        "5. We'll then show the image and print metadata"
      ],
      "metadata": {
        "id": "X9HzqdGnqxnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "random.seed(42)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. Pick up random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from peth name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "piIT2qq2q1BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "HjdTzr_wr8gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transforming data\n",
        "\n",
        "Before we can use our image data with PyTorch:\n",
        "\n",
        "1. Turn you target data into tensors (in our case, numercial representation of our images).\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`, we'll call these `Dataset` and `DataLoader`."
      ],
      "metadata": {
        "id": "eVstgpwBloeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "BQpcuGH4mTgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Tranforming data with `torchvision.transforms`\n",
        "\n",
        "Transforms help you get your images ready to be used with a model/perform data augmentation"
      ],
      "metadata": {
        "id": "VXrbAMl2mi9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize our images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "B5OUttjCmhbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img)"
      ],
      "metadata": {
        "id": "e1L6s8N2nm1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "  \"\"\"\n",
        "  Selects random images from a path of images and loads/transforms them then plots the original vs the transformed version\n",
        "  \"\"\"\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "  random_image_path = random.sample(image_paths, k=n)\n",
        "  for image_path in random_image_path:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].set_title(f\"original\\nSize: {f.size}\")\n",
        "      ax[0].axis(False)\n",
        "\n",
        "      # Transform and plot the target image\n",
        "      transformed_image = transform(f).permute(1, 2, 0)\n",
        "      ax[1].imshow(transformed_image)\n",
        "      ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
        "      ax[1].axis(\"off\")\n",
        "\n",
        "      fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "\n",
        "plot_transformed_images(image_paths=image_path_list,\n",
        "                          transform=data_transform,\n",
        "                          n=3,\n",
        "                          seed=None)"
      ],
      "metadata": {
        "id": "akM36zj7oAWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Option 1: Loading image data using `ImageFolder`\n",
        "\n",
        "We can load image classification data using `torchvision.datasets.ImageFolder`"
      ],
      "metadata": {
        "id": "pqwmgTfxqxRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir,\n",
        "                                  transform=data_transform, # a transform for the data\n",
        "                                  target_transform=None) # a transform for the label/target\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform)\n",
        "\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "U-5KmctQrHoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "c6gfIHooqw4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "VK0ij9LIqwwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of our dataset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "ARLoxDfHsTy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on the train_data Dataset to get a single image and label\n",
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image tensor:\\n {img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "id": "-W8W5SHAsYS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes\n",
        "print(f\"Original shapes: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permute: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(False)\n",
        "plt.title(class_names[label], fontsize=14)\n"
      ],
      "metadata": {
        "id": "b1MueEcQtr6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Turn loaded images into `DataLoader`'s\n",
        "\n",
        "A `DataLoader` is going to help us turn our `Dataset`'s int iterables and we can customize the `batch_size` so our model can see `batch_size` images at a time."
      ],
      "metadata": {
        "id": "fnLsQrZCuryS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our train and test datasets into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 1\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=os.cpu_count(),\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             num_workers=os.cpu_count(),\n",
        "                             shuffle=True)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "fLkq7e7WvGWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "QxlK7HCYv1XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "# Batch size will now be 1 you can change the batch size if you like\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape}\")"
      ],
      "metadata": {
        "id": "6wxFI-yKwCaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Option 2: Loading Image Data with a Custom `Dataset`\n",
        "\n",
        "1. Want to be able to load images from a file\n",
        "2. Want to be able to get class names from the Dataset\n",
        "3. Want to be able to get classes as dictionary from the Dataset\n",
        "\n",
        "Pros:\n",
        "* Can create a `Dataset` out of almost anything\n",
        "* Not limited to PyTorch pre-built `Dataset` functions\n",
        "\n",
        "Cons:\n",
        "* Even though you could create `Dataset` out of almost anything, it doesn't mean it will work...\n",
        "* Using a custom`Dataset` often results in us writing more code, which could be prone to errors or performance issues.\n",
        "\n",
        "All custom datasets in PyTorch often subclass, `torch.utils.data.Dataset`"
      ],
      "metadata": {
        "id": "M84k6W17wt7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "g3SA62zrwtqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "zPUM-Ux6yIVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Creating a helper function to get class names\n",
        "\n",
        "We want a function to:\n",
        "\n",
        "1. Get the class names using `os.scandir()` to traverse a target directory (ideally the directory is in standard image classification format).\n",
        "2. Raise an error if the class names aren't found (if this happens, there might be something wrong with the data)\n",
        "3. Turn the class names into a dict and a list and return them."
      ],
      "metadata": {
        "id": "0RBP4NkT4c24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for target directory\n",
        "target_directory = train_dir\n",
        "print(f\"Target dir: {target_directory}\")\n",
        "\n",
        "# Get the class names from the target directory\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "1JodXQE546Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "  \"\"\"Finds the class folfer names in a target directory.\"\"\"\n",
        "  # 1. Get the class names by scanning the target directory\n",
        "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "  # 2. Raise an error if class names could not be found\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}... please check file structure.\")\n",
        "\n",
        "  # 3. Create a dictionary of index labels (computers prefer numbers rather than strings as labels)\n",
        "  class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "WxSSTsHu5Ysg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "MhISJ1Ts6UQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Create a custom `Dataset` to replicate `ImageFolder`\n",
        "\n",
        "To create oru own custom dataset, we want to:\n",
        "\n",
        "1. Subclass `torch.utils.data.Dataset`\n",
        "2. Init our subclass with a target directory (the directory we'd like to get data from) as well as a transform if we'd like to transform our data.\n",
        "3. Create several attributes:\n",
        "  * paths - paths of our images\n",
        "  * transform - the transform we'd like to use\n",
        "  * classes - a list of the taget classes\n",
        "  * class_to_idx - a dict of the target classes mapped to integer labels\n",
        "4. Create a function to `load_images()`, this function will open an image\n",
        "5. Overwrite the `__len()__` method to return the length of our dataset\n",
        "6. Overwrite the `__getitem()__` method to return a given sample when passed an index"
      ],
      "metadata": {
        "id": "E5wG3L1m6_2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Write a custom dataset class\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "  # 2. Initialize our custom dataset\n",
        "  def __init__(self,\n",
        "               target_directory: str,\n",
        "               transform=None):\n",
        "    # 3. Create class attributes\n",
        "    # Get all of the image paths\n",
        "    self.paths = list(pathlib.Path(target_directory).glob(\"*/*jpg\"))\n",
        "    # Setup transform\n",
        "    self.transform = transform\n",
        "    # Create classes and class_to_idx attributes\n",
        "    self.classes, self.class_to_idx = find_classes(target_directory)\n",
        "\n",
        "  # 4. Create a function to load images\n",
        "  def load_image(self, index: int) -> Image.Image:\n",
        "    \"Opens an image via a pth and return it.\"\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  # 5. Overwrite __len__()\n",
        "  def __len__(self):\n",
        "    \"Returns the total number of samples.\"\n",
        "    return len(self.paths)\n",
        "\n",
        "  # 6. Overwrite __getitem__() method to return a particular sample\n",
        "  def __getitem__(self, index: int) -> Tuple[torch.tensor, int]:\n",
        "    \"Returns one sample of data, data and label (X, y).\"\n",
        "    img = self.load_image(index)\n",
        "    class_name = self.paths[index].parent.name # expects path in format: data_folder/class-Name/image.jpg\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    # Transform if necessary\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_idx # return data label (X, y)\n",
        "    else:\n",
        "      return img, class_idx # return untransformed img and label"
      ],
      "metadata": {
        "id": "lmqkdh_F78pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a transform\n",
        "from torchvision import transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "N9c77eDkNatS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out ImageFolderCustom\n",
        "train_data_custom = ImageFolderCustom(target_directory=train_dir,\n",
        "                                      transform=train_transforms)\n",
        "\n",
        "test_data_custom = ImageFolderCustom(target_directory=test_dir,\n",
        "                                     transform=test_transforms)"
      ],
      "metadata": {
        "id": "04B0bytUN-qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom, test_data_custom"
      ],
      "metadata": {
        "id": "Fesj7bOzOYIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(train_data_custom)"
      ],
      "metadata": {
        "id": "cKL7mhr6OaY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data), len(test_data_custom)"
      ],
      "metadata": {
        "id": "ZXFtL4XPOfOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes"
      ],
      "metadata": {
        "id": "P3DhnFu2Ok2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_to_idx"
      ],
      "metadata": {
        "id": "MIX9lDYzOhyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for equality between original ImageFolder Dataset and ImageFolderCustomDataset\n",
        "print(train_data_custom.classes == train_data.classes)\n",
        "print(test_data_custom.classes == test_data.classes)"
      ],
      "metadata": {
        "id": "wFPpZ7zAOnDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Create a function to display random images\n",
        "\n",
        "1. Take in a `Dataset` and a number of other parameters such as class names and how many images to visualize.\n",
        "2. To prevent the display getting out of hand, let's cap the number of images to see at 10.\n",
        "3. Set the random seed for reproducibility.\n",
        "4. Get a list of random sample indexes from the target dataset.\n",
        "5. Setup matplotlib plot.\n",
        "6. Loop through the random sample images and plot them with matplotlib\n",
        "7. Make sure the dimensions of our images line up with matplotlib (HWC)"
      ],
      "metadata": {
        "id": "vd9H64-oPLxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creata fucntion to take a dataset\n",
        "def display_random_images(dataset: torch.utils.data.Dataset,\n",
        "                         classes: List[str] = None,\n",
        "                         n: int = 10,\n",
        "                         display_shape: bool = True,\n",
        "                         seed: int = None):\n",
        "  # 2. Adjust display if n is too high\n",
        "  if n > 10:\n",
        "    n = 10\n",
        "    display_shape = False\n",
        "    print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display\")\n",
        "\n",
        "  # 3. Set the seed\n",
        "  if seed:\n",
        "    random.seed(42)\n",
        "\n",
        "  # 4. Get random sample indexes\n",
        "  random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "  # 5. Setup plot\n",
        "  plt.figure(figsize=(16, 8))\n",
        "\n",
        "  # 6. Loop through random indexes and plot them with matplotlib\n",
        "  for i, target_sample in enumerate(random_samples_idx):\n",
        "    target_image, target_label = dataset[target_sample][0], dataset[target_sample][1]\n",
        "\n",
        "    # 7. Adjust tensor dimensions for plotting\n",
        "    target_image_adjust = target_image.permute(1, 2, 0) # [color_channels, height, width] -> [height, width, color_channels]\n",
        "\n",
        "    # Plot adjusted sample\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(target_image_adjust)\n",
        "    plt.axis(False)\n",
        "    if classes:\n",
        "      title = f\"Class: {classes[target_label]}\"\n",
        "      if display_shape:\n",
        "        title = title + f\"\\nShape: {target_image_adjust.shape}\"\n",
        "    plt.title(title)"
      ],
      "metadata": {
        "id": "pkVMgDOmPrMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from the ImageFolder created Dataset\n",
        "display_random_images(train_data,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=None)"
      ],
      "metadata": {
        "id": "A_s5m_-aR7p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from the ImageFolderCustom created Dataset\n",
        "display_random_images(train_data_custom,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=None)"
      ],
      "metadata": {
        "id": "-iL8y9AkSSIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Turn custom loaded images into `DataLoader`'s\n"
      ],
      "metadata": {
        "id": "jxF_sIYbd1vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=True)\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=False)"
      ],
      "metadata": {
        "id": "eFqmn3Hqd7AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_custom, test_dataloader_custom"
      ],
      "metadata": {
        "id": "YbRQ6g8IeQQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image and label from custom dataloder\n",
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "\n",
        "# Print out sahpes\n",
        "img_custom.shape, label_custom.shape"
      ],
      "metadata": {
        "id": "KVTCwb-FeqMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Other forms of transform (data augmentation)\n",
        "\n",
        "Data augmentation is process of artificially adding diversity to your training data.\n",
        "\n",
        "In the case of image data, this may mean applying various image transformations to the training images.\n",
        "\n",
        "This practice hoefully results in a model that's is more generalizable to unseen data."
      ],
      "metadata": {
        "id": "11V_-tZxfww6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at trivialaugment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(22, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "dbfr_R7ohG3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "image_path_list[:10]"
      ],
      "metadata": {
        "id": "XG94pfhTh60W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot random transformed images\n",
        "plot_transformed_images(image_paths=image_path_list,\n",
        "                        transform=train_transform,\n",
        "                        n=3,\n",
        "                        seed=None)"
      ],
      "metadata": {
        "id": "DtFXqVUhiF1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model 0: TinyVGG without data augmentation"
      ],
      "metadata": {
        "id": "e8tVd7FfzTm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Creating transforms and loading data for Model 0"
      ],
      "metadata": {
        "id": "fsdrZsFGz_1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple transform\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "EU9dyvyyzgxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and transform data\n",
        "from torchvision import datasets\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir,\n",
        "                                         transform=simple_transform)\n",
        "\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
        "                                           transform=simple_transform)\n",
        "\n",
        "# 2. Turn the datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup batch size and number of works\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataloader_simple = DataLoader(dataset=train_data_simple,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "ucGM-vTP0Skw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Create TinyVGG model class"
      ],
      "metadata": {
        "id": "KKOAccji1Pap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture copying TinyVGG from CNN explainer.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                      stride=2) # default stride value is same as kernel_size\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                      stride=2) # default stride value is same as kernel_size\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print(x.shape)\n",
        "    return x"
      ],
      "metadata": {
        "id": "pbqWhKoQ1TBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, # number of color channels in our image data\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(class_names)).to(device)\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "id": "i1TBFD_k3WYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Try a forward pass on a single image (to test the model)"
      ],
      "metadata": {
        "id": "CyIdfEV24K3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single image batch\n",
        "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "IrgMyUGg4HrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trye to forward batch\n",
        "model_0(image_batch.to(device))"
      ],
      "metadata": {
        "id": "knbrwZst4fhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Use `torchinfo` to get an idea of the shapes going through our model"
      ],
      "metadata": {
        "id": "WR-v7bRm7T3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0, input_size=[1, 3, 64, 64])"
      ],
      "metadata": {
        "id": "3ByNYtXS7hFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 Create train and test loops functions\n",
        "\n",
        "* `train_step()` - takes a model and dataloader and trains the model on the dataloader.\n",
        "* `test_step()` - takes in a model and dataloader and evaluates the model on the dataloader."
      ],
      "metadata": {
        "id": "yAM6JN0o82G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train_step()\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device = device):\n",
        "  # Put the model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # loo[ through the data loader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Send data to the target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimzer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy metric\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "cSUArYNE81zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test step\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device = device):\n",
        "  # put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference mode\n",
        "  with torch.inference_mode():\n",
        "    # Loop through DataLoader batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send data to the target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred_logits = model(X)\n",
        "\n",
        "      # 2. Calculate the loss\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      # Calculate the accuracy\n",
        "      test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n",
        "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get avergae loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "VjtsB8yc-x4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.6 Creating a `train()` function to combine `train_step()` and `test_step()`"
      ],
      "metadata": {
        "id": "U1jDxCV2CE_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Create a train function that takes in various model paramaters + optimizer + loss function\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5,\n",
        "          device: torch.device = device):\n",
        "  # 2. Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []}\n",
        "\n",
        "  # 3. Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       optimizer=optimizer,\n",
        "                                       device=device)\n",
        "\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "\n",
        "    # 4. Print out what's happening\n",
        "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc} | Test loss: {test_loss} | Test acc: {test_acc}\")\n",
        "\n",
        "    # 5. Update results dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "UnHvQMAlCMHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.7 Train and evaluate model 0"
      ],
      "metadata": {
        "id": "8m-EpADME35t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape=3,\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# train model_0\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader_simple,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "SDuuCpMOE7i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.8 Plot the loss curves of Model 0\n",
        "\n",
        "A **loss curve** is a way of plotting your model's progress over time."
      ],
      "metadata": {
        "id": "2Gwvor-vHIyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model_0 results keys\n",
        "model_0_results.keys()"
      ],
      "metadata": {
        "id": "zF8egIguHIjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "  \"\"\"Plots training curves of a results dictionary.\"\"\"\n",
        "  # Get the loss values of the results dictionary (training and test)\n",
        "  loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "\n",
        "  # Get the accuracy values of the results dictionary (training and test)\n",
        "  accuracy = results[\"train_acc\"]\n",
        "  test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "  # Figure out how many epochs there were\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "  # Setup a plot\n",
        "  plt.figure(figsize=(15, 7))\n",
        "\n",
        "  # Plot the loss\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, label=\"train_loss\")\n",
        "  plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot the accuracy\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "  plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "s1bH2beZHiB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(results=model_0_results)"
      ],
      "metadata": {
        "id": "bEol1D5CJChN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Model 1: TinyVGG with Data Augmentation\n",
        "\n",
        "Now let's try another modelling experiment this time using the same model as before with some data augmentation."
      ],
      "metadata": {
        "id": "zw37OgjyNCBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 Create transform with data augmentation"
      ],
      "metadata": {
        "id": "YmJ4JUM9NOR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CReate training transform with TrivialAugment\n",
        "from torchvision import transforms\n",
        "train_transform_trivial = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform_simple = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "UX0uDxN5NVUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2 Create a train and test `Dataset` and `DataLoader` with data augmentation"
      ],
      "metadata": {
        "id": "EFtZ74kINzWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn image folders into datasets\n",
        "from torchvision import datasets\n",
        "train_data_augmented = datasets.ImageFolder(root=train_dir,\n",
        "                                            transform=train_transform_trivial)\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
        "                                        transform=test_transform_simple)"
      ],
      "metadata": {
        "id": "eaaaB6NPN56E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our Datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_dataloader_augmented = DataLoader(dataset=train_data_augmented,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=NUM_WORKERS)\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "4HDwOOWROaHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3 Construct and train Model 1\n",
        "\n",
        "This time we'll be using the same model architecture except this time we've augmentest the training data."
      ],
      "metadata": {
        "id": "jW1DDdGCPBg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model_1 and send it to the target device\n",
        "torch.manual_seed(42)\n",
        "model_1 = TinyVGG(input_shape=3,\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data_augmented.classes)).to(device)\n",
        "\n",
        "model_1"
      ],
      "metadata": {
        "id": "c_gmnvkfPLe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set randoms seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Setup loss_function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_1.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model 1\n",
        "model_1_results = train(model=model_1,\n",
        "                       train_dataloader=train_dataloader_augmented,\n",
        "                       test_dataloader=test_dataloader_simple,\n",
        "                       loss_fn=loss_fn,\n",
        "                       optimizer=optimizer,\n",
        "                       epochs=NUM_EPOCHS,\n",
        "                       device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "zL5fhi9uRyww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4 Plot the loss curves of model 1\n",
        "A **loss curve* helps you evaluate your models performance over time."
      ],
      "metadata": {
        "id": "CdBLA7uDcox7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_1_results)"
      ],
      "metadata": {
        "id": "x9Jz7l35cofH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Compare model results\n",
        "After evaluating our modeling experiments on their own, it's important to compare them to each other.\n",
        "\n",
        "there's few different ways to do this:\n",
        "\n",
        "1. Hard coding\n",
        "2. PyTorch + Tensorboard\n",
        "3. Weights and Biases\n",
        "4. MLFlow"
      ],
      "metadata": {
        "id": "aHFdbTEwc68W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "model_0_df = pd.DataFrame(model_0_results)\n",
        "model_1_df = pd.DataFrame(model_1_results)\n",
        "model_0_df"
      ],
      "metadata": {
        "id": "o-jiBifAdaCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(model_0_df))\n",
        "\n",
        "# Plot train loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"Model 1\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test loss\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"Model 1\")\n",
        "plt.title(\"Test Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot train accuracy\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"Model 1\")\n",
        "plt.title(\"Train Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test accuracy\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"Model 0\")\n",
        "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"Model 1\")\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "dnAtbGmTdqxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Making a prediction on a custom image\n",
        "\n",
        "Although we've trainerd a model on a custom data... how do you make a prediction on a sample/image"
      ],
      "metadata": {
        "id": "qxQtLkS0fq41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download custom image\n",
        "import requests\n",
        "\n",
        "# Setup custom image path\n",
        "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
        "\n",
        "# Download the image if it doesn't already exist\n",
        "if not custom_image_path.is_file():\n",
        "  with open(custom_image_path, \"wb\") as f:\n",
        "    # When downloading from GitHub, need to use the \"raw\" file link\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg?raw=true\")\n",
        "    print(f\"Downloading {custom_image_path}...\")\n",
        "    f.write(request.content)\n",
        "else:\n",
        "  print(f\"{custom_image_path} already exists, skipping download.\")"
      ],
      "metadata": {
        "id": "AGXM1Qn5gBGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.1 Loading in a custom image with PyTorch\n",
        "\n",
        "We have to make sure our custom image is in the same format as the data our model was trained on.\n",
        "\n",
        "* In tensor form with datatype (torch.float32)\n",
        "* On shape 64x64x3\n",
        "* On the right device"
      ],
      "metadata": {
        "id": "hkC_z66LhgLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# Read in custom image\n",
        "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))\n",
        "\n",
        "print(f\"Custom image tensor: {custom_image_uint8}\")\n",
        "print(f\"Custom image shape: {custom_image_uint8.shape}\")\n",
        "print(f\"Custom image datatype: {custom_image_uint8.dtype}\")"
      ],
      "metadata": {
        "id": "79D6u7sHiDpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image_uint8.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "gVMDss5FiiMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2 Making a prediction on a custom image with a trained PyTorch model"
      ],
      "metadata": {
        "id": "hePGhUz8imo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the custom image and convert to torch.float32\n",
        "custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32) / 255\n",
        "custom_image"
      ],
      "metadata": {
        "id": "M2StJ7swi7er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transform pipeline to resice the image\n",
        "custom_image_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64))\n",
        "])\n",
        "\n",
        "# Transform target image\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "# Print out the shapes\n",
        "print(f\"Original shape: {custom_image.shape}\")\n",
        "print(f\"Transformed shape: {custom_image_transformed.shape}\")"
      ],
      "metadata": {
        "id": "iH2CqNcxj1u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image_transformed.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "h9Cp48lokTeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image_transformed.shape, custom_image_transformed.unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "id": "weE9IpwSlGex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction on an image in uint8 format\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=0).to(device))\n",
        "custom_image_pred"
      ],
      "metadata": {
        "id": "4zCb20lKkb6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, to make a prediction on a custom image we had to:\n",
        "* Laod the image and turn it into a tensor\n",
        "* Make sure the image was the same datatype as the model (torch.float32)\n",
        "* Make sure trhe image was the same shape as the data the model was trained on (3x64x64) with a batch size... (1, 3, 64, 64)\n",
        "* Make sure the image was on the same device as our model"
      ],
      "metadata": {
        "id": "HY3k5v92lX-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert logits -> prediction probabilities\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
        "custom_image_pred_probs"
      ],
      "metadata": {
        "id": "g9ib76-ElT-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities -> predcition labels\n",
        "custom_image_pred_labels = torch.argmax(custom_image_pred_probs, dim=1).cpu()\n",
        "custom_image_pred_labels"
      ],
      "metadata": {
        "id": "KYXaI0-MmdXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[custom_image_pred_labels]"
      ],
      "metadata": {
        "id": "SISCqGIymtc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.3 Putting custom image predcition together: building a function\n",
        "\n",
        "Ideal outcome:\n",
        "\n",
        "A function where we pass an image path to and have our model predict on that image and plot the image + prediction"
      ],
      "metadata": {
        "id": "tE7da4O-m0q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str] = None,\n",
        "                        transform: torchvision.transforms = None,\n",
        "                        device: torch.device = None):\n",
        "  \"\"\"Makes a prediction on a target image with a trained model and plots the image and prediction.\"\"\"\n",
        "  # Load in the image\n",
        "  target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "\n",
        "  # Divide the image pixel values by 255 to get them between [0, 1]\n",
        "  target_image = target_image / 255\n",
        "\n",
        "  # Transform if necessary\n",
        "  if transform:\n",
        "    target_image = transform(target_image)\n",
        "\n",
        "  # Make sure the model is on the target device\n",
        "  model.to(device)\n",
        "\n",
        "  # Turn on eavl/inference mode and make a prediction\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    # Add an extra dimension to the imahe (this is the batch dimension)\n",
        "    target_image = target_image.unsqueeze(0)\n",
        "\n",
        "    # Make a prediction on the image with an extra dimension\n",
        "    target_image_pred = model(target_image.to(device))\n",
        "\n",
        "  # Convert logits -> prediction probabilities\n",
        "  target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "  # COnvert prediction probabilities -> prediction labels\n",
        "  target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "  # Plot the image alongside the prediction and prediction probabilities\n",
        "  plt.imshow(target_image.squeeze().permute(1, 2, 0))\n",
        "  if class_names:\n",
        "    title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "  else:\n",
        "    title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "  plt.title(title)\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "Pk-o91b_m0cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot_image(model=model_1,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "Xw17Q_D1uh8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}