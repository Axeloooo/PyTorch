{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyt8WVlrM5+05cWmqklBAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axeloooo/PyTorch/blob/main/01_pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. PyTorch Workflow"
      ],
      "metadata": {
        "id": "to5IxrrbTO98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering = {\n",
        "    1: \"data (prepare and load)\",\n",
        "    2: \"build model\",\n",
        "    3: \"fitting the model to data (training)\",\n",
        "    4: \"making predictions and evaluating a model (inference)\",\n",
        "    5: \"saving and loading a model\",\n",
        "    6: \"putting it all together\"\n",
        "}\n",
        "what_were_covering"
      ],
      "metadata": {
        "id": "8DLgxgnETQQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "2aWnlOAWVb-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data (Preparing and Loading)\n",
        "\n",
        "Data can be almost anyhting in machine learning\n",
        "* Excel spreadsheet\n",
        "* Images of any kind\n",
        "* Videos\n",
        "* Audio\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "1. Get data into a numerical represenattion\n",
        "2. Build a model to learn patterns in that numerial representation\n",
        "\n",
        "To showcase this, let's create some *known* data using the linear regression formula.\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with *known* **parameters**"
      ],
      "metadata": {
        "id": "SiR2B35lVr9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "id": "7spxUCVXVrA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets (one of the most important concepts in machine learning in general)\n",
        "\n",
        "Let's create a training and test set with our data"
      ],
      "metadata": {
        "id": "cSQqSolXZC7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train/test split\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "a9ZRCmvTZJrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing Data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14})"
      ],
      "metadata": {
        "id": "J6DXJGKcbHh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "id": "J7StIO4xciY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building model\n",
        "\n",
        "First PyTorch model\n",
        "\n",
        "What our model does:\n",
        "* Start with random values (weight & bias)\n",
        "* look at training data and adjust the random values to better represent the ideal values (the weigfht & bias values we used to create the data)\n",
        "\n",
        "How does it do so?\n",
        "\n",
        "Through two main algorithms:\n",
        "1. Gradient descent\n",
        "2. Backpropagation"
      ],
      "metadata": {
        "id": "haCMu4m6c6Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# Create a linear regression model class\n",
        "class LinearRegressionModel(nn.Module): ## <- almost everyhting in PyTorch inherits from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight\n",
        "                                            requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
        "                                            dtype=torch.float)) # <- PyTorch loves the datatype torch.float32\n",
        "\n",
        "    self.bias = nn.Parameter(torch.randn(1, # <- start with a random bias and try to adjust it to the ideal bias\n",
        "                                         requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
        "                                         dtype=torch.float)) # <- PyTorch loves the datatype torch.float32\n",
        "\n",
        "  # Forward method to define the computation in the model\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
        "    return self.weights * x + self.bias # this is the linear regression"
      ],
      "metadata": {
        "id": "Mf3pI9b_dWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* `torch.nn` - Contains all the buildings blocks for computational graphs (a neural network could be considered a computational graph)\n",
        "* `torch.nn.Parameter` - What parameters should our model try and leanr, often a PyTorch layer from `torch.nn` will set these for us\n",
        "* `torch.nn.Module` - The base class for all neural network modules, if you inherit it you should override `forward()` method\n",
        "* `torch.optim` - This where the optimizers in PyTorch live, they will help with gradient descent\n",
        "* `def forward()` - All nn.Module subclasses require you to overwrite `forward()`, this method defines what happens"
      ],
      "metadata": {
        "id": "ImfA3m9ciDhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "We can check our model parameters or what is inside our model by using `.parameters()`"
      ],
      "metadata": {
        "id": "WcVHryqDtyFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "2TLsajDngKif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "XwLyLOeBu_Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making poredition using `torch.inference_mode()`\n",
        "\n",
        "To check our moidel's predictive power, let's see how weel it predicts `y_test` bassed on `X_test`\n",
        "\n",
        "When we pass data through our model, it's going to run it through the `forward()` method."
      ],
      "metadata": {
        "id": "jVMdSNF2dIA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "5ueJCwMxdglT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "OwhWx_MHePoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions= y_preds)"
      ],
      "metadata": {
        "id": "dLTHlh6ReSkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train model\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
        "\n",
        "Or in other words from a poor representation of the data to a better represeantation of the data.\n",
        "\n",
        "One way to measure how poor or how wrong your models predictions are is to use a loss functions.\n",
        "\n",
        "* Note: Loss function may also be called cost function or criterion in different areas.\n",
        "\n",
        "Things we need to train:\n",
        "* **Loss Function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
        "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (e.g. weight and bias) to improve the loss function.\n",
        "  * Inside the optimizer you'll often have to set two parameters:\n",
        "      * `params` - the model parameters you'd like to optimize\n",
        "      * `lr` - the learning rate is a jyperparameter that defines how big/small the optimizer changes the parameters with each step\n",
        "\n",
        "And specifically for PyTorch we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "oeSWsUlIgaVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Setup an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.01) # learning rate = possible the most important hyperparameter you can set"
      ],
      "metadata": {
        "id": "TpH6DWU-h9ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a training loop in PyTorch\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "0. Loop through the data\n",
        "1. Forward pass (this involves data moving through our model's `forward()` functions) to make predictions on data - also called forward propagation\n",
        "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loos backward - move backwards through the network to calculate the gradients of each of the parameters of ouyr model with respect to the loss (**backpropagation**)\n",
        "5. Optimizer steo - use the optimizer to adjust the models parameters to try and improve the loss (**gradient descent**)"
      ],
      "metadata": {
        "id": "JnBKkHnhzj55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch is one loop through the data... (this is a hyperparameter because w've set it )\n",
        "epochs = 200\n",
        "\n",
        "# Tracking different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "# 0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step() # by default how the optimizer changes will accumulate through the loop... we have to zero them above in step 3\n",
        "\n",
        "  # Testing\n",
        "  model_0.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode(): # turns offf gradient tracking & a couple more things behind the scenes\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    #2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
        "    print(model_0.state_dict())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RcxjTWAa1K0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(torch.tensor(loss_values).numpy())"
      ],
      "metadata": {
        "id": "Gq-l3vHLglFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and Test Loss Curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "WqpHuyPlgCY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)"
      ],
      "metadata": {
        "id": "AZtEOGnruZ55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=test_pred)"
      ],
      "metadata": {
        "id": "pwlSHkKLuhea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving a model in PyTorch\n",
        "\n",
        "There are three main methods you should know about for saving an loading models in PyTorch.\n",
        "\n",
        "1. `torch.save()` - allows you to save a PyTorch object in Python's pickle format\n",
        "2. `torch.load()` - allows you to load a saved PyToch object\n",
        "3. `torch.nn.Module.load_state_dict()` - this allows to load a model's daves state dictionary"
      ],
      "metadata": {
        "id": "apSW2Us2kSVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our PyTorch model\n",
        "model_0.state_dict()\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f\"Saving model to {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "ZdavtIfGk6X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "id": "kIHz7tLqqWte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a PyTorch model\n",
        "\n",
        "Since we saved our model's `state_dict()` rather the entire model, we'll create a new instance of our model calss and load the sabed `state_dict()` into that."
      ],
      "metadata": {
        "id": "cw_vhT0Vq2Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "MKwYAEPEsDMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "id": "OIgIL5fmsFCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "id": "TEkn0xoaswt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "id": "nGVH4Ubwsz4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare loaded model preds with original preds\n",
        "y_preds_new  == loaded_model_preds"
      ],
      "metadata": {
        "id": "3YrmsoIRtMhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Putting it all together\n",
        "\n",
        "Let's go through the steps above and see it all in one place"
      ],
      "metadata": {
        "id": "-WJszRyuvABo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch and matplotlib\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "uk_DM6JsvY7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create device-agnostic code\n",
        "\n",
        "This means if we've got access to a GPU, our code will use it (for potentially faster computing).\n",
        "\n",
        "If no GPU is available, the code will default to using CPU."
      ],
      "metadata": {
        "id": "FrIrB5etvrL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "wT4jKOyrvoGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Data"
      ],
      "metadata": {
        "id": "gEHNygnWvKSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some data using the linear regression formula of y = weight * X + bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create range values\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y (features and labels)\n",
        "X = torch.arange(start=start, end=end, step=step).unsqueeze(dim=1)\n",
        "y  = weight * X + bias\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "id": "kOenL7vLvMEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "kbTbb28ixKso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing Data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14})"
      ],
      "metadata": {
        "id": "ezT5JBNzyFgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data\n",
        "plot_predictions(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "5_8O2oHbx0Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Building a PyTorch Linear model"
      ],
      "metadata": {
        "id": "RDAinT6SyHlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear model by subclassing nn.Module\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Use nn.Linear() for creating the model parameters\n",
        "    self.linear_layer = nn.Linear(in_features=1,\n",
        "                                  out_features=1)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "# Set the manual seed\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "id": "jQa28pSayLq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Training model\n",
        "\n",
        "For training we need:\n",
        "* Loss function\n",
        "* Optimizer\n",
        "* Training loop\n",
        "* Testing loop"
      ],
      "metadata": {
        "id": "4L8zfJaA0hn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model current device\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "uvqNTW3c086r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to use the target device\n",
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "POOh5mxO0xiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss() # same as MAE\n",
        "\n",
        "# Setup an optimize\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.01,)"
      ],
      "metadata": {
        "id": "K_Ox2Cn81TVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write a trainig loop\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "# Put data on the target device (device agnostic code for the data)\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "\n",
        "  # 1. Forward propagation\n",
        "  y_pred = model_1(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(X_test)\n",
        "\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out whats happening\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "id": "n_ERu1E_1r5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "sYVzu7883NsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Making and evaluating predictions"
      ],
      "metadata": {
        "id": "Dik2HIu_47lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trun model into evaluation mode\n",
        "model_1.eval()\n",
        "\n",
        "# Make predictions on the test data\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_1(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "c5h4FnL-5ATv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our modl prediction viasually\n",
        "plot_predictions(predictions=y_preds.cpu())"
      ],
      "metadata": {
        "id": "06qk7Trl5dGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5 Saving and loading a trained model"
      ],
      "metadata": {
        "id": "jB2Gv_lX5y-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f\"Saving model to {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_1.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "Yp3sMi9Y52jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "5406gTMN63RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a PyTorch model\n",
        "\n",
        "# Create a new instance of linear regression model V2\n",
        "loaded_model_1 = LinearRegressionModelV2()\n",
        "\n",
        "# Load the saved model_1 state_dict\n",
        "loaded_model_1.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Put the loaded model to device\n",
        "loaded_model_1.to(device)"
      ],
      "metadata": {
        "id": "YRbAz8vL66yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(loaded_model_1.parameters()).device"
      ],
      "metadata": {
        "id": "GDq99kcC7bLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1.state_dict()"
      ],
      "metadata": {
        "id": "9N6noZe27ezu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model\n",
        "loaded_model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_1_preds = loaded_model_1(X_test)\n",
        "\n",
        "y_preds == loaded_model_1_preds"
      ],
      "metadata": {
        "id": "70DkzuTN7hpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}