{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLW5M2CfwS3yCcnfmjgpWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axeloooo/PyTorch/blob/main/07_pytorch_experiment_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07. PyTorch Experiment Tracking\n",
        "\n",
        "Machine Learning is very experimental.\n",
        "\n",
        "In order to figure out which experiments are worth pursuing, that's where **experiement tracking** comes in, it helps you to figure out what doesn't work so you can figure out what **does** work.\n",
        "\n",
        "In this notebook, we're going to see an example of programmatically tracking experiments."
      ],
      "metadata": {
        "id": "cxy4hAjM3XGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "mCXlAENpCzq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "CPKnTBpdCR5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "CsINrHnwCfB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "vL8zq5_0CrZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds()"
      ],
      "metadata": {
        "id": "LScyb16ECsTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "Want to get pizza, steak, sushi images.\n",
        "\n",
        "So we can run experiments building FoodVision Mini and see which model performs best."
      ],
      "metadata": {
        "id": "65vZJvULDXiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_data(\n",
        "    source: str,\n",
        "    destination: str,\n",
        "    remove_source: bool = True\n",
        ") -> Path:\n",
        "  \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
        "\n",
        "    Args:\n",
        "        source (str): A link to a zipped file containing data.\n",
        "        destination (str): A target directory to unzip data to.\n",
        "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path to downloaded data.\n",
        "\n",
        "    Example usage:\n",
        "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                      destination=\"pizza_steak_sushi\")\n",
        "  \"\"\"\n",
        "  # Setup path to data folder\n",
        "  data_path = Path(\"data/\")\n",
        "  image_path = data_path / destination\n",
        "\n",
        "  # If the image folder doesn't exist, create it\n",
        "  if image_path.is_dir():\n",
        "    print(f\"[INFO] {image_path} directory already exists, skipping download.\")\n",
        "  else:\n",
        "    print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download the target data\n",
        "    target_file = Path(source).name\n",
        "    with open(data_path / target_file, \"wb\") as f:\n",
        "      request = requests.get(source)\n",
        "      print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
        "      f.write(request.content)\n",
        "\n",
        "    # Unzip file\n",
        "    with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "      print(f\"[INFO] Unzipping {target_file} data ...\")\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file if needed\n",
        "    if remove_source:\n",
        "      os.remove(data_path / target_file)\n",
        "\n",
        "  return image_path"
      ],
      "metadata": {
        "id": "t3eIlNsHDrXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = download_data(\n",
        "    source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "    destination=\"pizza_steak_sushi\"\n",
        ")"
      ],
      "metadata": {
        "id": "-ROsw-mHFZ2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "pfI6GqxOFyWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create DataLoaders with manual transforms\n",
        "\n",
        "The goal with transforms is to ensure your custom data is formatted in a reproducible way as well as a way that will suit pretrained models."
      ],
      "metadata": {
        "id": "kN0MxY6SF025"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directories\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "x3qzbdd1F-_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ImageNet normalization levels (turns all images into similar distribution as ImageNet)\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "# Create transform pipeline manually\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "print(f\"Manually created transforms: {manual_transforms}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=manual_transforms, # use manually created transforms\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "T1DLX9B_G1AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Create DataLoaders using automatically created transforms\n",
        "\n",
        "The same principles applies for automatic transforms: we want our custom data in the same format as a pretrained model was trained on."
      ],
      "metadata": {
        "id": "P6IXwy6zHvaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "# Setup pretrained weights (plenty of these available in torchvision.models)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "\n",
        "# Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
        "automatic_transforms = weights.transforms()\n",
        "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=automatic_transforms, # use automatic created transforms\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "7EpJJ-mhIodr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Getting a pretrained model, freezing the base layers and changing the classifier head"
      ],
      "metadata": {
        "id": "Sjr8DNJqJu3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This is how a pretrained model would be created in torchvision > 0.13, it will be deprecated in future versions.\n",
        "# model = torchvision.models.efficientnet_b0(pretrained=True).to(device) # OLD\n",
        "\n",
        "# Download the pretrained weights for EfficientNet_B0\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # NEW in torchvision 0.13, \"DEFAULT\" means \"best weights available\"\n",
        "\n",
        "# Setup the model with the pretrained weights and send it to the target device\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "# View the output of the model\n",
        "model"
      ],
      "metadata": {
        "id": "E9J-KBlwJwJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers by setting requires_grad attribute to False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Since we're creating a new layer with random weights (torch.nn.Linear),\n",
        "# let's set the seeds\n",
        "set_seeds()\n",
        "\n",
        "# Update the classifier head to suit our problem\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    nn.Dropout(\n",
        "        p=0.2,\n",
        "        inplace=True\n",
        "    ),\n",
        "    nn.Linear(\n",
        "        in_features=1280,\n",
        "        out_features=len(class_names),\n",
        "        bias=True\n",
        "    ).to(device)\n",
        ")"
      ],
      "metadata": {
        "id": "Gcc3QaYSTixx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# Get a summary of the model (uncomment for full output)\n",
        "summary(\n",
        "    model,\n",
        "    input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
        "    verbose=0,\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "    col_width=20,\n",
        "    row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "G-Hoozf-UQCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train a single model and track results"
      ],
      "metadata": {
        "id": "MAGvRek6U_G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "U8fOiMKQVCbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To track experiments we're going to use TensorBoard. And to interact with TensorBoard we can use PyTorch's SummaryWriter."
      ],
      "metadata": {
        "id": "EY9K2GzsVozw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
        "    !pip install -q tensorboard\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Create a writer with all default settings\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "NaxvUrsPW8Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from going_modular.going_modular.engine import train_step, test_step\n",
        "\n",
        "# Import train() function from:\n",
        "# https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        dataloader=test_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        ### New: Experiment tracking ###\n",
        "        # Add loss results to SummaryWriter\n",
        "        writer.add_scalars(main_tag=\"Loss\",\n",
        "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                            \"test_loss\": test_loss},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        # Add accuracy results to SummaryWriter\n",
        "        writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                            \"test_acc\": test_acc},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        # Track the PyTorch model architecture\n",
        "        writer.add_graph(model=model,\n",
        "                         # Pass in an example input\n",
        "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
        "\n",
        "    # Close the writer\n",
        "    writer.close()\n",
        "\n",
        "    ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "GKzZCaMIVyAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "# Note: Not using engine.train() since the original script isn't updated to use writer\n",
        "set_seeds()\n",
        "results = train(model=model,\n",
        "                train_dataloader=train_dataloader,\n",
        "                test_dataloader=test_dataloader,\n",
        "                optimizer=optimizer,\n",
        "                loss_fn=loss_fn,\n",
        "                epochs=5,\n",
        "                device=device)"
      ],
      "metadata": {
        "id": "k9A9DKtAYXqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the model results\n",
        "results"
      ],
      "metadata": {
        "id": "p-cOB4xvbIq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. View our model's results with TensorBoard"
      ],
      "metadata": {
        "id": "iTujqRjfaqk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example code to run in Jupyter or Google Colab Notebook (uncomment to try it out)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "uxU_lMvyauoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Create a function to prepare a `SummaryWriter()` instance\n",
        "\n",
        "By default our `SummaryWriter()` class saves to our `log_dir` parameter.\n",
        "\n",
        "How about if we wanted to save different experiments to different folders?\n",
        "\n",
        "In essence, one experiment = one folder.\n",
        "\n",
        "For example, we'd like to track:\n",
        "* Experiment date/timestamp\n",
        "* Experiment name\n",
        "* Model name\n",
        "* Extra - is there anything else that should be tracked?\n",
        "\n",
        "Let's create a function to create a `SummaryWriter()` instance to take all of these things into account.\n",
        "\n",
        "So ideally we end up tracking experiments to a dicrectory:\n",
        "\n",
        "`runs/YYYY-MM-DD/experiment_name/model_name/extra`"
      ],
      "metadata": {
        "id": "wxQSA-SLdD_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
        "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
        "\n",
        "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
        "\n",
        "    Where timestamp is the current date in YYYY-MM-DD format.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): Name of experiment.\n",
        "        model_name (str): Name of model.\n",
        "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
        "\n",
        "    Example usage:\n",
        "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
        "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "                               model_name=\"effnetb2\",\n",
        "                               extra=\"5_epochs\")\n",
        "        # The above is the same as:\n",
        "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "\n",
        "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
        "\n",
        "    if extra:\n",
        "        # Create log directory path\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "    else:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "8nIUwc7Md2zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example writer\n",
        "example_writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "                               model_name=\"effnetb0\",\n",
        "                               extra=\"5_epochs\")"
      ],
      "metadata": {
        "id": "6_f0e3oLelLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Update the `train()` function to include a `writer` parameter"
      ],
      "metadata": {
        "id": "CMvKHtNAh9oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Add writer parameter to train()\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
        "          ) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Stores metrics to specified writer log_dir if present.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "      writer: A SummaryWriter() instance to log model results to.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "\n",
        "        ### New: Use the writer parameter to track experiments ###\n",
        "        # See if there's a writer, if so, log to it\n",
        "        if writer:\n",
        "            # Add results to SummaryWriter\n",
        "            writer.add_scalars(main_tag=\"Loss\",\n",
        "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                                \"test_loss\": test_loss},\n",
        "                               global_step=epoch)\n",
        "            writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                                \"test_acc\": test_acc},\n",
        "                               global_step=epoch)\n",
        "\n",
        "            # Close the writer\n",
        "            writer.close()\n",
        "        else:\n",
        "            pass\n",
        "    ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "6tlp6oOyiZWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Setting up a series of modelling experiments\n"
      ],
      "metadata": {
        "id": "haRfwhWAi-pQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 What kind of experiments should you run?\n",
        "\n",
        "The number of machine learning experiemnts you can run, is like the number of different models you can build... almost limitless.\n",
        "\n",
        "However, you can't test everything...\n",
        "\n",
        "So what should you test?\n",
        "* Change the number of epochs\n",
        "* Change the number of hidden layers/units\n",
        "* Change the amount of data\n",
        "* Change the learning rate\n",
        "* Try different kinds of dat augmentation\n",
        "* Choose a different model architecture"
      ],
      "metadata": {
        "id": "omSSnjYpjNqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 What experiments are we going to run?\n",
        "\n",
        "We're going to turn three dials:\n",
        "1. Model size - EffnetB0 vs EffnetB2 (in terms of number of parameters)\n",
        "2. Dataset size - 10% of pizza, steak, sushi images vs 20% (generally more data = better results)\n",
        "3. Training time - 5 epochs vs 10 epochs (generally longer training time = better results, up to a point)\n",
        "\n",
        "To begin, we're still keeping things relatively small so that our experiments run quickly."
      ],
      "metadata": {
        "id": "JKKbmxz0keaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Download different datasets\n",
        "\n",
        "We want two datasets:\n",
        "\n",
        "1. Pizza, steak, sushi 10%\n",
        "2. Pizza, steak, sushi 20%"
      ],
      "metadata": {
        "id": "VJsuxuedmQd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download 10 percent and 20 percent training data (if necessary)\n",
        "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                                     destination=\"pizza_steak_sushi\")\n",
        "\n",
        "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                     destination=\"pizza_steak_sushi_20_percent\")"
      ],
      "metadata": {
        "id": "T2VbOZjlmrsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training directory paths\n",
        "train_dir_10_percent = data_10_percent_path / \"train\"\n",
        "train_dir_20_percent = data_20_percent_path / \"train\"\n",
        "\n",
        "# Setup testing directory paths (note: use the same test dataset for both to compare the results)\n",
        "test_dir = data_10_percent_path / \"test\"\n",
        "\n",
        "# Check the directories\n",
        "print(f\"Training directory 10%: {train_dir_10_percent}\")\n",
        "print(f\"Training directory 20%: {train_dir_20_percent}\")\n",
        "print(f\"Testing directory: {test_dir}\")"
      ],
      "metadata": {
        "id": "ZBSsS4-Mn2Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Transform Datasets and create DataLoaders\n",
        "\n",
        "We'll transform our data in a few ways:\n",
        "\n",
        "1. Resize the image to (224, 224)\n",
        "2. Make sure image tensor values are between [0, 1]\n",
        "3. Normalize the images so they have the same data distribution as ImageNet"
      ],
      "metadata": {
        "id": "Zk1lPbGznZTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Create a transform to normalize data distribution to be inline with ImageNet\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
        "                                 std=[0.229, 0.224, 0.225]) # values per colour channel [red, green, blue]\n",
        "\n",
        "# Compose transforms into a pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Resize the images\n",
        "    transforms.ToTensor(), # 2. Turn the images into tensors with values between 0 & 1\n",
        "    normalize # 3. Normalize the images so their distributions match the ImageNet dataset\n",
        "])"
      ],
      "metadata": {
        "id": "DbSBJtSunX8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create 10% training and test DataLoaders\n",
        "train_dataloader_10_percent, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir_10_percent,\n",
        "    test_dir=test_dir,\n",
        "    transform=simple_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Create 20% training and test data DataLoders\n",
        "train_dataloader_20_percent, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir_20_percent,\n",
        "    test_dir=test_dir,\n",
        "    transform=simple_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n",
        "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10_percent)}\")\n",
        "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20_percent)}\")\n",
        "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(test_dataloader)} (all experiments will use the same test set)\")\n",
        "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
      ],
      "metadata": {
        "id": "pJuc_aydo-5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 Create feature extractor models\n",
        "\n",
        "We want two functions:\n",
        "\n",
        "1. Creates a `torchvision.models.efficientnet_b0()` feature extractor with a frozen backbone/base layers and a custom classifier head.\n",
        "2. Creates a `torchvision.models.efficientnet_b2()` feature extractor with a frozen backbone/base layers and s custom classifier head."
      ],
      "metadata": {
        "id": "QoCEOA7lpYSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchinfo import summary\n",
        "\n",
        "# 1. Create an instance of EffNetB2 with pretrained weights\n",
        "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT # \"DEFAULT\" means best available weights\n",
        "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
        "\n",
        "# 2. Get a summary of standard EffNetB2 from torchvision.models (uncomment for full output)\n",
        "summary(model=effnetb2,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")\n",
        "\n",
        "# 3. Get the number of in_features of the EfficientNetB2 classifier layer\n",
        "# print(f\"Number of in_features to final layer of EfficientNetB2: {len(effnetb2.classifier.state_dict()['1.weight'][0])}\")"
      ],
      "metadata": {
        "id": "0GGXlhxdp3Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "# Get num out features (one for each class pizza, steak, sushi)\n",
        "OUT_FEATURES = len(class_names)\n",
        "\n",
        "# Create an EffNetB0 feature extractor\n",
        "def create_effnetb0():\n",
        "    # 1. Get the base model with pretrained weights and send to target device\n",
        "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "    # 2. Freeze the base model layers\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 3. Set the seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # 4. Change the classifier head\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.2),\n",
        "        nn.Linear(in_features=1280, out_features=OUT_FEATURES)\n",
        "    ).to(device)\n",
        "\n",
        "    # 5. Give the model a name\n",
        "    model.name = \"effnetb0\"\n",
        "    print(f\"[INFO] Created new {model.name} model.\")\n",
        "    return model\n",
        "\n",
        "# Create an EffNetB2 feature extractor\n",
        "def create_effnetb2():\n",
        "    # 1. Get the base model with pretrained weights and send to target device\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    model = torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
        "\n",
        "    # 2. Freeze the base model layers\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 3. Set the seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # 4. Change the classifier head\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3),\n",
        "        nn.Linear(in_features=1408, out_features=OUT_FEATURES)\n",
        "    ).to(device)\n",
        "\n",
        "    # 5. Give the model a name\n",
        "    model.name = \"effnetb2\"\n",
        "    print(f\"[INFO] Created new {model.name} model.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "UKDTQ3Wsr0zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb0 = create_effnetb0()\n",
        "\n",
        "# Get an output summary of the layers in our EffNetB0 feature extractor model (uncomment to view full output)\n",
        "summary(model=effnetb0,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "J-l1_81Gr75h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2 = create_effnetb2()\n",
        "\n",
        "# Get an output summary of the layers in our EffNetB2 feature extractor model (uncomment to view full output)\n",
        "summary(model=effnetb2,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "IAhlWpajsADD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.6 Create experiments and setup training code\n",
        "\n"
      ],
      "metadata": {
        "id": "FkS411IJtBqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create epoch list\n",
        "num_epochs = [5, 10]\n",
        "\n",
        "# Create models list (need to create a new model for each experiment)\n",
        "models = [\"effnetb0\", \"effnetb2\"]\n",
        "\n",
        "# Create a DataLoaders dictionary\n",
        "train_dataloaders = {\"data_10_percent\": train_dataloader_10_percent,\n",
        "                     \"data_20_percent\": train_dataloader_20_percent}"
      ],
      "metadata": {
        "id": "JlXe9s6WtLeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from going_modular.going_modular.utils import save_model\n",
        "\n",
        "# 1. Set the random seeds\n",
        "set_seeds(seed=42)\n",
        "\n",
        "# 2. Keep track of experiment numbers\n",
        "experiment_number = 0\n",
        "\n",
        "# 3. Loop through each DataLoader\n",
        "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
        "\n",
        "    # 4. Loop through each number of epochs\n",
        "    for epochs in num_epochs:\n",
        "\n",
        "        # 5. Loop through each model name and create a new model based on the name\n",
        "        for model_name in models:\n",
        "\n",
        "            # 6. Create information print outs\n",
        "            experiment_number += 1\n",
        "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
        "            print(f\"[INFO] Model: {model_name}\")\n",
        "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "            print(f\"[INFO] Number of epochs: {epochs}\")\n",
        "\n",
        "            # 7. Select the model\n",
        "            if model_name == \"effnetb0\":\n",
        "                model = create_effnetb0() # creates a new model each time (important because we want each experiment to start from scratch)\n",
        "            else:\n",
        "                model = create_effnetb2() # creates a new model each time (important because we want each experiment to start from scratch)\n",
        "\n",
        "            # 8. Create a new loss and optimizer for every model\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "            # 9. Train target model with target dataloaders and track experiments\n",
        "            train(model=model,\n",
        "                  train_dataloader=train_dataloader,\n",
        "                  test_dataloader=test_dataloader,\n",
        "                  optimizer=optimizer,\n",
        "                  loss_fn=loss_fn,\n",
        "                  epochs=epochs,\n",
        "                  device=device,\n",
        "                  writer=create_writer(experiment_name=dataloader_name,\n",
        "                                       model_name=model_name,\n",
        "                                       extra=f\"{epochs}_epochs\"))\n",
        "\n",
        "            # 10. Save the model to file so we can get back the best model\n",
        "            save_filepath = f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
        "            save_model(model=model,\n",
        "                       target_dir=\"models\",\n",
        "                       model_name=save_filepath)\n",
        "            print(\"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "khSk8ZrWtl8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. View experiments in TensorBoard"
      ],
      "metadata": {
        "id": "V64rfnrQzLaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing TensorBoard in Jupyter and Google Colab Notebooks (uncomment to view full TensorBoard instance)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "hA5RZWpGzNLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best performing model was:\n",
        "* Model: EffNetB2\n",
        "* Dataset: Pizza, steak, sushi 20%\n",
        "* Epochs: 10\n",
        "\n",
        "And the overal trend of all the results was the more data, bigger model and longer training time generally led to better results."
      ],
      "metadata": {
        "id": "CySIpQqY0KHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Load in the best model and make predictions with it\n",
        "\n",
        "This is our best model filepath: `models/07_effnetb2_data_20_percent_10_epochs.pth`"
      ],
      "metadata": {
        "id": "61cZ3zFm1lHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the best model filepath\n",
        "best_model_path = \"models/07_effnetb2_data_20_percent_10_epochs.pth\"\n",
        "\n",
        "# Instantiate a new instance of EffNetB2 (to load the saved state_dict() to)\n",
        "best_model = create_effnetb2()\n",
        "\n",
        "# Load the saved best model state_dict()\n",
        "best_model.load_state_dict(torch.load(best_model_path))"
      ],
      "metadata": {
        "id": "AO2d5sX60xg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal: Create a FoodVision Mini model that performs well enough and is able to run on a mobile device/web browser."
      ],
      "metadata": {
        "id": "Vdisfv7a2C2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model file size\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "effnetb2_model_size = Path(best_model_path).stat().st_size // (1024*1024)\n",
        "print(f\"EfficientNetB2 feature extractor model size: {effnetb2_model_size} MB\")"
      ],
      "metadata": {
        "id": "vMNgJ0wJ19po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import function to make predictions on images and plot them\n",
        "# See the function previously created in section: https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set\n",
        "from going_modular.going_modular.predictions import pred_and_plot_image\n",
        "\n",
        "# Get a random list of 3 images from 20% test set\n",
        "import random\n",
        "num_images_to_plot = 3\n",
        "test_image_path_list = list(Path(data_20_percent_path / \"test\").glob(\"*/*.jpg\")) # get all test image paths from 20% dataset\n",
        "test_image_path_sample = random.sample(population=test_image_path_list,\n",
        "                                       k=num_images_to_plot) # randomly select k number of images\n",
        "\n",
        "# Iterate through random test image paths, make predictions on them and plot them\n",
        "for image_path in test_image_path_sample:\n",
        "    pred_and_plot_image(model=best_model,\n",
        "                        image_path=image_path,\n",
        "                        class_names=class_names,\n",
        "                        image_size=(224, 224))"
      ],
      "metadata": {
        "id": "O_FFuIXu3DdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 Predict on a custom image with the best model"
      ],
      "metadata": {
        "id": "Tv4B35Bc3xkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download custom image\n",
        "import requests\n",
        "\n",
        "# Setup custom image path\n",
        "custom_image_path = Path(\"data/04-pizza-dad.jpeg\")\n",
        "\n",
        "# Download the image if it doesn't already exist\n",
        "if not custom_image_path.is_file():\n",
        "    with open(custom_image_path, \"wb\") as f:\n",
        "        # When downloading from GitHub, need to use the \"raw\" file link\n",
        "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
        "        print(f\"Downloading {custom_image_path}...\")\n",
        "        f.write(request.content)\n",
        "else:\n",
        "    print(f\"{custom_image_path} already exists, skipping download.\")\n",
        "\n",
        "# Predict on custom image\n",
        "pred_and_plot_image(model=model,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names)"
      ],
      "metadata": {
        "id": "nlOR7w-z35NM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}